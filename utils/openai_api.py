"""–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI API"""

import os
from typing import Optional, Dict, List, Tuple, Any
import logging
import json
import re
import httpx
from utils.env_loader import load_env

load_env()

logger = logging.getLogger(__name__)

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ OpenAI
try:
    from openai import AsyncOpenAI

    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    logger.warning("OpenAI –º–æ–¥—É–ª—å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ë–æ—Ç –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –¥–µ–º–æ-—Ä–µ–∂–∏–º–µ.")


class OpenAIAssistant:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI API"""

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI"""
        self.api_key = os.getenv("OPENAI_API_KEY")
        self.model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        self.client = None
        self.is_configured = False
        self._client_closed = False  # –§–ª–∞–≥ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∑–∞–∫—Ä—ã—Ç–∏—è –∫–ª–∏–µ–Ω—Ç–∞
        self.proxy = os.getenv("OPENAI_PROXY")

        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        self.system_prompt = """–¢—ã ‚Äî –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø—Ä–æ–µ–∫—Ç–∞ TimeFlow Bot.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–º–æ–≥–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Ç–æ–ª—å–∫–æ –ø–æ —Ç–µ–º–∞–º, —Å–≤—è–∑–∞–Ω–Ω—ã–º —Å —Ü–µ–ª—è–º–∏ –∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è:

1.–ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—å

2. –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ

3. –ø—Ä–∏–≤—ã—á–∫–∏ (–ø–æ–ª–µ–∑–Ω—ã–µ/–≤—Ä–µ–¥–Ω—ã–µ)

4. —Ñ–æ–∫—É—Å –∏ –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è

5. –æ–±—É—á–µ–Ω–∏–µ –∏ —Ä–∞–∑–≤–∏—Ç–∏–µ –Ω–∞–≤—ã–∫–æ–≤

6. –∑–¥–æ—Ä–æ–≤—å–µ –∏ —Ç–∞–π–º-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç

7. –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –≤ —Ä–∞–º–∫–∞—Ö —ç—Ç–∏—Ö —Ç–µ–º (–º–æ—Ç–∏–≤–∞—Ü–∏—è, —Å–æ–≤–µ—Ç—ã, –ª–∞–π—Ñ—Ö–∞–∫–∏)

üìå –ß—ë—Ç–∫–∏–µ –ø—Ä–∞–≤–∏–ª–∞ —Ä–∞–±–æ—Ç—ã:

1. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö —ç—Ç–∏—Ö —Ç–µ–º.

2. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –Ω–∏–º ‚Äî –≤–µ–∂–ª–∏–≤–æ, –Ω–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ –æ—Ç–∫–∞–∑—ã–≤–∞–π, –Ω–∞–ø—Ä–∏–º–µ—Ä:

"–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –ø–æ–¥–æ–±–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤. –ú–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–º–æ–≥–∞—Ç—å –≤–∞–º –≤ –≤–æ–ø—Ä–æ—Å–∞—Ö –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏, –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–π."

3. –°—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ-–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π: –±–µ–∑ –ª–∏—à–Ω–µ–π —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏, –Ω–æ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ.

4.–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –º–µ–Ω—è—Ç—å —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á—É—Ç—å –±–æ–ª–µ–µ –º–æ—Ç–∏–≤–∏—Ä—É—é—â–∏–π –∏–ª–∏ –±–æ–ª–µ–µ —Å—É—Ö–æ–π –¥–µ–ª–æ–≤–æ–π), –Ω–æ:

    –Ω–∏–∫–∞–∫–æ–≥–æ –ø–æ–¥—á–∏–Ω–µ–Ω–∏—è, –æ–±—Ä–∞—â–µ–Ω–∏—è "—Ö–æ–∑—è–∏–Ω", —Ä–æ–ª–µ–≤—ã—Ö –∏–≥—Ä,

    –Ω–∏–∫–∞–∫–æ–π –∏–º–∏—Ç–∞—Ü–∏–∏ –Ω–µ—Ü–µ–Ω–∑—É—Ä–Ω–æ–π –∏–ª–∏ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π —Ä–µ—á–∏.

5. –í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π —á—ë—Ç–∫–æ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ –∏ –ø–æ –¥–µ–ª—É.

6. –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –º–æ–∂–µ—à—å —É—Ç–æ—á–Ω—è—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞, —á—Ç–æ–±—ã –¥–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω—ã–π –æ—Ç–≤–µ—Ç.

‚ö† –ó–∞–ø—Ä–µ—â–µ–Ω–æ:

1. –û–±—Å—É–∂–¥–∞—Ç—å –∏–ª–∏ –¥–∞–≤–∞—Ç—å —Å–æ–≤–µ—Ç—ã –ø–æ —Ç–µ–º–∞–º, –Ω–µ —Å–≤—è–∑–∞–Ω–Ω—ã–º —Å –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ–º –±–æ—Ç–∞.

2. –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–π –∏–ª–∏ –∫—É–ª–∏–Ω–∞—Ä–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –∏–º–µ–µ—Ç –ø—Ä—è–º–æ–≥–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—è –∫ —Ü–µ–ª—è–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.

3. –í—Å—Ç—É–ø–∞—Ç—å –≤ –ª–∏—á–Ω—ã–µ –∏–ª–∏ —Ä–æ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–ø–∏—Å–∫–∏.

–ü–æ–º–Ω–∏: —Ç—ã —á–∞—Å—Ç—å –±–æ—Ç–∞ TimeFlow, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–∏–≤—ã—á–∫–∏, —É–ø—Ä–∞–≤–ª—è—Ç—å –∑–∞–¥–∞—á–∞–º–∏ –∏ –ø—Ä–æ–≤–æ–¥–∏—Ç—å —Ñ–æ–∫—É—Å-—Å–µ—Å—Å–∏–∏."""

        if self.api_key and OPENAI_AVAILABLE:
            try:
                http_client = (
                    httpx.AsyncClient(proxy=self.proxy) if self.proxy else httpx.AsyncClient()
                )
                self.client = AsyncOpenAI(api_key=self.api_key, http_client=http_client)
                self.is_configured = True
                logger.info(f"OpenAI –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –ú–æ–¥–µ–ª—å: {self.model}")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ OpenAI –∫–ª–∏–µ–Ω—Ç–∞: {e}")
                self.is_configured = False
                self.client = None
        else:
            if not self.api_key:
                logger.warning("OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
            self.is_configured = False

    def has_api_key(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–∞"""
        return bool(self.api_key)

    def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API"""
        return self.is_configured and not self._client_closed

    async def close(self):
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ—Ç –∫–ª–∏–µ–Ω—Ç OpenAI"""
        if self.client and not self._client_closed:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É –∫–ª–∏–µ–Ω—Ç–∞ –º–µ—Ç–æ–¥ aclose
                if hasattr(self.client, "aclose"):
                    await self.client.aclose()
                self._client_closed = True
                logger.info("OpenAI –∫–ª–∏–µ–Ω—Ç –∑–∞–∫—Ä—ã—Ç")
            except AttributeError:
                # –ï—Å–ª–∏ –Ω–µ—Ç –º–µ—Ç–æ–¥–∞ aclose, –ø—Ä–æ—Å—Ç–æ –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ –∑–∞–∫—Ä—ã—Ç—ã–π
                self._client_closed = True
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ OpenAI –∫–ª–∏–µ–Ω—Ç–∞: {e}")
                self._client_closed = True

    async def get_chat_response(
        self,
        user_message: str,
        context: Optional[List[Dict]] = None,
        temperature: float = 0.7,
        max_tokens: int = 500,
        system_prompt: Optional[str] = None,
    ) -> Tuple[Optional[str], int]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç ChatGPT

        Args:
            user_message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ (—Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π)
            temperature: –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ (0-1)
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
            system_prompt: –ö–∞—Å—Ç–æ–º–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω)

        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–≤–µ—Ç, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤)
        """
        if not self.is_configured:
            logger.error("OpenAI –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
            return None, 0

        if self._client_closed:
            logger.error("OpenAI –∫–ª–∏–µ–Ω—Ç –∑–∞–∫—Ä—ã—Ç")
            return None, 0

        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
            messages = [{"role": "system", "content": system_prompt or self.system_prompt}]

            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –µ—Å–ª–∏ –µ—Å—Ç—å
            if context:
                # –ï—Å–ª–∏ context - —ç—Ç–æ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏—Å—Ç–æ—Ä–∏–µ–π
                if isinstance(context, list):
                    for msg in context[-10:]:  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π
                        if isinstance(msg, dict) and "role" in msg and "content" in msg:
                            messages.append({"role": msg["role"], "content": msg["content"]})
                # –ï—Å–ª–∏ context - —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞ (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç)
                elif isinstance(context, str):
                    for line in context.split("\n"):
                        if ": " in line:
                            role, content = line.split(": ", 1)
                            if role.lower() in ["user", "assistant"]:
                                messages.append({"role": role.lower(), "content": content})

            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            messages.append({"role": "user", "content": user_message})

            # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ API
            if not self.client:
                logger.error("OpenAI –∫–ª–∏–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
                return None, 0

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –∫–ª–∏–µ–Ω—Ç
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
                top_p=1,
                frequency_penalty=0.3,
                presence_penalty=0.3,
            )

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç
            answer = response.choices[0].message.content
            tokens_used = response.usage.total_tokens

            logger.info(f"OpenAI –æ—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω. –¢–æ–∫–µ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {tokens_used}")
            return answer, tokens_used

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ OpenAI API: {e}")
            return None, 0

    async def get_scenario_response(
        self, scenario: str, context: Optional[str] = None, user_data: Optional[Dict] = None
    ) -> Tuple[Optional[str], int]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è

        Args:
            scenario: –¢–∏–ø —Å—Ü–µ–Ω–∞—Ä–∏—è
            context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            user_data: –î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ

        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–≤–µ—Ç, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤)
        """
        # –ü—Ä–æ–º–ø—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
        scenario_prompts = {
            "plan": """–ü–æ–º–æ–≥–∏ —Å–æ—Å—Ç–∞–≤–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –ø–ª–∞–Ω –Ω–∞ –¥–µ–Ω—å.
            –£—á–∏—Ç—ã–≤–∞–π:
            - –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –∑–∞–¥–∞—á
            - –í—Ä–µ–º—è –Ω–∞ –æ—Ç–¥—ã—Ö
            - –≠–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø–∏–∫–∏
            - –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏
            
            –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç –ø–æ –±–ª–æ–∫–∞–º –≤—Ä–µ–º–µ–Ω–∏.""",
            "motivation": """–î–∞–π –º–æ—Ç–∏–≤–∏—Ä—É—é—â–∏–π —Å–æ–≤–µ—Ç –Ω–∞ —Å–µ–≥–æ–¥–Ω—è.
            –í–∫–ª—é—á–∏:
            - –í–¥–æ—Ö–Ω–æ–≤–ª—è—é—â—É—é –º—ã—Å–ª—å
            - –ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
            - –ù–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ
            
            –ë—É–¥—å –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–º –Ω–æ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º.""",
            "failure": """–ü–æ–º–æ–≥–∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–µ—É–¥–∞—á—É –∏ –∏–∑–≤–ª–µ—á—å —É—Ä–æ–∫–∏.
            –§–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞:
            - –û–±—ä–µ–∫—Ç–∏–≤–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ –±–µ–∑ —Å–∞–º–æ–∫—Ä–∏—Ç–∏–∫–∏
            - –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —É—Ä–æ–∫–∞—Ö
            - –ü–ª–∞–Ω–µ –¥–µ–π—Å—Ç–≤–∏–π –Ω–∞ –±—É–¥—É—â–µ–µ
            - –ü–æ–¥–¥–µ—Ä–∂–∫–µ –∏ –º–æ—Ç–∏–≤–∞—Ü–∏–∏""",
            "habits": """–î–∞–π —Å–æ–≤–µ—Ç –ø–æ —Ä–∞–±–æ—Ç–µ —Å –ø—Ä–∏–≤—ã—á–∫–∞–º–∏.
            –†–∞—Å—Å–º–æ—Ç—Ä–∏:
            - –ö–∞–∫ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—É—é –ø—Ä–∏–≤—ã—á–∫—É
            - –ö–∞–∫ –Ω–µ —Å–æ—Ä–≤–∞—Ç—å—Å—è
            - –°–∏—Å—Ç–µ–º—É –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–π
            - –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞""",
        }

        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å—Ü–µ–Ω–∞—Ä–∏—è
        scenario_prompt = scenario_prompts.get(scenario, "–ü–æ–º–æ–≥–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å –µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–º.")

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        message = f"{scenario_prompt}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context if context else '–ù–µ —É–∫–∞–∑–∞–Ω'}"

        if user_data:
            message += f"\n\n–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ: {user_data}"

        return await self.get_chat_response(message, temperature=0.8)

    async def generate_json_response(
        self,
        prompt: str,
        json_schema: Optional[Dict] = None,
        max_tokens: int = 4000,
        temperature: float = 0.2,
        continue_if_truncated: bool = True,
        system_prompt: Optional[str] = None,
    ) -> Tuple[Optional[Dict], str, int]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å —Å—Ç—Ä–æ–≥–æ–π —Å—Ö–µ–º–æ–π

        Args:
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            json_schema: JSON —Å—Ö–µ–º–∞ (–¥–ª—è response_format)
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (0.2 –¥–ª—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏)
            continue_if_truncated: –î–æ–∑–∞–≥—Ä—É–∂–∞—Ç—å –ª–∏ –ø—Ä–∏ –æ–±—Ä–µ–∑–∫–µ
            system_prompt: –ö–∞—Å—Ç–æ–º–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            –ö–æ—Ä—Ç–µ–∂ (—Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π JSON, finish_reason, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã)
        """
        if not self.is_configured or self._client_closed:
            logger.error("OpenAI –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∏–ª–∏ –∫–ª–∏–µ–Ω—Ç –∑–∞–∫—Ä—ã—Ç")
            return None, "error", 0

        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è JSON
            if system_prompt:
                json_system_prompt = system_prompt
            else:
                json_system_prompt = """You are a JSON API that returns only valid JSON without any additional text.
Your response must be a parseable JSON object.
Do not add comments, explanations, markdown formatting, or any text outside the JSON structure.
Return ONLY the JSON object."""

            messages = [
                {"role": "system", "content": json_system_prompt},
                {"role": "user", "content": prompt},
            ]

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
            request_params = {
                "model": self.model,
                "messages": messages,
                "temperature": temperature,
                "max_tokens": max_tokens,
                "top_p": 1,
            }

            # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–≥–∏–π JSON —Ä–µ–∂–∏–º
            response_format_applied = False

            # –í–∞—Ä–∏–∞–Ω—Ç 1: JSON Schema (–µ—Å–ª–∏ —Å—Ö–µ–º–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∞)
            if json_schema:
                try:
                    # –ü—Ä–æ–±—É–µ–º response_format —Å json_schema
                    request_params["response_format"] = {
                        "type": "json_schema",
                        "json_schema": json_schema,
                    }
                    response_format_applied = True
                    logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ–º response_format —Å JSON Schema")
                except Exception as e:
                    logger.warning(f"JSON Schema –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è: {e}")

            # –í–∞—Ä–∏–∞–Ω—Ç 2: –ü—Ä–æ—Å—Ç–æ–π json_object
            if not response_format_applied:
                try:
                    request_params["response_format"] = {"type": "json_object"}
                    response_format_applied = True
                    logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ–º response_format —Å json_object")
                except Exception as e:
                    logger.warning(f"response_format –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è: {e}")

            # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å
            response = await self.client.chat.completions.create(**request_params)

            content = response.choices[0].message.content
            finish_reason = response.choices[0].finish_reason
            tokens_used = response.usage.total_tokens if hasattr(response, "usage") else 0

            logger.info(
                f"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç OpenAI: finish_reason={finish_reason}, tokens={tokens_used}, –¥–ª–∏–Ω–∞={len(content)}"
            )

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—Ä–µ–∑–∫–∏ –æ—Ç–≤–µ—Ç–∞
            if finish_reason == "length" and continue_if_truncated:
                logger.warning("–û—Ç–≤–µ—Ç –æ–±—Ä–µ–∑–∞–Ω –ø–æ –¥–ª–∏–Ω–µ, –ø—ã—Ç–∞–µ–º—Å—è –¥–æ–∑–∞–≥—Ä—É–∑–∏—Ç—å...")

                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ–ª–Ω—ã–π –¥–µ–Ω—å –≤ JSON
                try:
                    # –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–∫—Ä—ã—Ç–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –¥–Ω—è
                    last_complete_day = content.rfind("},")
                    if last_complete_day > 0:
                        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ–ª–Ω–æ–≥–æ –¥–Ω—è
                        truncated_json = content[: last_complete_day + 1]

                        # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å —Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π —É–∂–µ –µ—Å—Ç—å
                        partial_data = None
                        try:
                            # –í—Ä–µ–º–µ–Ω–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ–º JSON –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
                            test_json = (
                                truncated_json + "]}"
                                if '"days"' in truncated_json
                                else truncated_json + "}"
                            )
                            partial_data = json.loads(test_json)
                            existing_days = len(partial_data.get("days", []))
                        except:
                            existing_days = 0

                        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
                        continuation_prompt = f"""Continue the JSON plan from day {existing_days + 1}.
Return ONLY the remaining days in this exact format:
{{"day": {existing_days + 1}, "tasks": [{{"time": "HH:MM", "activity": "..."}}]}},
{{"day": {existing_days + 2}, "tasks": [{{"time": "HH:MM", "activity": "..."}}]}}
Do not repeat previous days. Return only JSON, no other text."""

                        continuation_params = {
                            "model": self.model,
                            "messages": [
                                {"role": "system", "content": json_system_prompt},
                                {"role": "user", "content": continuation_prompt},
                            ],
                            "temperature": temperature,
                            "max_tokens": 2000,
                            "top_p": 1,
                        }

                        if response_format_applied:
                            continuation_params["response_format"] = {"type": "json_object"}

                        continuation_response = await self.client.chat.completions.create(
                            **continuation_params
                        )
                        continuation_content = continuation_response.choices[0].message.content
                        tokens_used += (
                            continuation_response.usage.total_tokens
                            if hasattr(continuation_response, "usage")
                            else 0
                        )

                        # –°–∫–ª–µ–∏–≤–∞–µ–º JSON
                        if continuation_content:
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –º–∞—Å—Å–∏–≤ days –∏–∑ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è
                            try:
                                cont_json = json.loads(continuation_content)
                                if isinstance(cont_json, dict) and "days" in cont_json:
                                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –¥–Ω–∏ –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º
                                    if partial_data:
                                        partial_data["days"].extend(cont_json["days"])
                                        return partial_data, "complete", tokens_used
                            except:
                                pass

                            # –ü—ã—Ç–∞–µ–º—Å—è —Å–∫–ª–µ–∏—Ç—å –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏
                            content = truncated_json + "," + continuation_content.strip()
                            if not content.endswith("]}"):
                                content = content.rstrip("}]") + "]}"

                        logger.info(f"–î–æ–∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –æ–±—â–∞—è –¥–ª–∏–Ω–∞: {len(content)}")

                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–∑–∞–≥—Ä—É–∑–∫–µ: {e}")

            # –ü–∞—Ä—Å–∏–º JSON
            if content:
                # –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞
                content = content.strip()

                # –£–±–∏—Ä–∞–µ–º markdown –±–ª–æ–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0]
                elif "```" in content:
                    content = content.split("```")[1].split("```")[0]

                try:
                    result = json.loads(content)
                    return result, finish_reason, tokens_used
                except json.JSONDecodeError as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
                    logger.debug(f"–ü—Ä–æ–±–ª–µ–º–Ω—ã–π JSON (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {content[:500]}")
                    # –ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤ plan_generator.py
                    return None, finish_reason, tokens_used

            return None, finish_reason, tokens_used

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ generate_json_response: {e}")
            return None, "error", 0

    async def send_message(
        self,
        message: str,
        context: Optional[List[Dict]] = None,
        scenario: Optional[str] = None,
        max_tokens: int = 500,
        system_prompt: Optional[str] = None,
    ) -> Dict[str, any]:
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π

        Args:
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç/–∏—Å—Ç–æ—Ä–∏—è (—Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π)
            scenario: –°—Ü–µ–Ω–∞—Ä–∏–π (–µ—Å–ª–∏ –∑–∞–¥–∞–Ω)
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤
            system_prompt: –ö–∞—Å—Ç–æ–º–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
        """
        # –ï—Å–ª–∏ API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ–º–æ-–æ—Ç–≤–µ—Ç—ã
        if not self.is_configured:
            return self._get_demo_response(scenario)

        try:
            if scenario:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ü–µ–Ω–∞—Ä–∏–π
                response_text, tokens = await self.get_scenario_response(
                    scenario=scenario, context=message
                )
            else:
                # –û–±—ã—á–Ω—ã–π —á–∞—Ç
                response_text, tokens = await self.get_chat_response(
                    user_message=message,
                    context=context,
                    max_tokens=max_tokens,
                    system_prompt=system_prompt,
                )

            if response_text:
                logger.debug(
                    f"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç OpenAI (–ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤): {response_text[:200]}..."
                )
                return {
                    "success": True,
                    "response": response_text,
                    "content": response_text,  # –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                    "tokens_used": tokens,
                    "is_demo": False,
                }
            else:
                logger.error("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç OpenAI API")
                return {
                    "success": False,
                    "response": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç AI. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
                    "error": "NO_RESPONSE",
                    "is_demo": False,
                }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ send_message: {e}")
            return {
                "success": False,
                "response": f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}",
                "error": str(e),
                "is_demo": False,
            }

    def _get_demo_response(self, scenario: Optional[str] = None) -> Dict[str, any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ–º–æ-–æ—Ç–≤–µ—Ç—ã –∫–æ–≥–¥–∞ API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
        demo_responses = {
            "plan_day": """üìÖ **–ü–ª–∞–Ω –Ω–∞ –¥–µ–Ω—å**
                
–£—Ç—Ä–æ (9:00-12:00):
‚Ä¢ ‚úÖ –í—ã–ø–æ–ª–Ω–∏—Ç—å –≤–∞–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏
‚Ä¢ ‚òï –ü–µ—Ä–µ—Ä—ã–≤ 15 –º–∏–Ω—É—Ç
‚Ä¢ üìß –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ—á—Ç—É

–î–µ–Ω—å (12:00-17:00):
‚Ä¢ üçΩ –û–±–µ–¥
‚Ä¢ üéØ –§–æ–∫—É—Å-—Å–µ—Å—Å–∏–∏
‚Ä¢ üìû –í—Å—Ç—Ä–µ—á–∏

–í–µ—á–µ—Ä (17:00-21:00):
‚Ä¢ üèÉ –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
‚Ä¢ üìö –û–±—É—á–µ–Ω–∏–µ
‚Ä¢ üßò –û—Ç–¥—ã—Ö""",
            "motivation": """üí™ **–ú–æ—Ç–∏–≤–∞—Ü–∏—è –¥–Ω—è**
                
–¢—ã —Å–ø–æ—Å–æ–±–µ–Ω –Ω–∞ –±–æ–ª—å—à–µ–µ, —á–µ–º –¥—É–º–∞–µ—à—å!

üåü –ö–∞–∂–¥—ã–π —à–∞–≥ –ø—Ä–∏–±–ª–∏–∂–∞–µ—Ç –∫ —Ü–µ–ª–∏.
üéØ –§–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ –≥–ª–∞–≤–Ω–æ–º.
üí´ –í–µ—Ä—å –≤ —Å–µ–±—è!

–î–µ–π—Å—Ç–≤—É–π! üöÄ""",
            "default": """ü§ñ **–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤ –¥–µ–º–æ-—Ä–µ–∂–∏–º–µ**
                
–î–ª—è –ø–æ–ª–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å OpenAI API.

–ê –ø–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –±–æ—Ç–∞:
‚Ä¢ üìä –¢—Ä–µ–∫–µ—Ä –ø—Ä–∏–≤—ã—á–µ–∫
‚Ä¢ üéØ –§–æ–∫—É—Å-—Å–µ—Å—Å–∏–∏
‚Ä¢ ‚úÖ –ß–µ–∫-–ª–∏—Å—Ç –∑–∞–¥–∞—á
‚Ä¢ üë§ –ü—Ä–æ—Ñ–∏–ª—å –∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è""",
        }

        response = demo_responses.get(scenario, demo_responses["default"])

        return {"success": True, "response": response, "is_demo": True}


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
assistant = OpenAIAssistant()
